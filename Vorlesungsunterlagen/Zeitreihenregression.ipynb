{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1efea320-503d-4d48-9480-0749747d87d3",
   "metadata": {},
   "source": [
    "#### Business Analytics FHDW 2025\n",
    "# Time Series\n",
    "## Regressionsbasierte Vorhersagen\n",
    "\n",
    "Wir nutzen wieder *Amtrak.csv* mit seinen Fahrgastzahlen. Die *ridership*-Zeitreihe leiten wir uns wie im Beispiel davor daraus ab und transformieren auch wieder die Monatsdaten in einen Zeitindex. Die etwas aufwändigere, wiederkehrende grafische Darstellung packen wir zu Teilen in Funktionen `graphLayout` und `singleGraphLayout`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b143c64-0740-402c-89fe-eca15d0c9d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tsa import tsatools\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics import tsaplots\n",
    "\n",
    "def regressionSummary(y_true, y_predicted):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_predicted = np.asarray(y_predicted)\n",
    "    y_residuals = y_true - y_predicted\n",
    "    metrics = [\n",
    "        ('Summe Abweichungen', sum(y_residuals)),\n",
    "        ('Summe absolute Abweichungen', sum(abs(y_residuals))),\n",
    "        ('Mittlerer Fehler', sum(y_residuals) / len(y_residuals)),\n",
    "        ('Mittlerer absoluter Fehler', sum(abs(y_residuals)) / len(y_residuals)),\n",
    "        ('Wurzel des durchschnittlichen Fehlerquadrats', np.sqrt(mean_squared_error(y_true, y_predicted)))\n",
    "    ]\n",
    "    if all(yt != 0 for yt in y_true):\n",
    "        metrics.extend([\n",
    "            ('Mittlerer prozentualer Fehler', 100 * sum(y_residuals / y_true) / len(y_residuals)),\n",
    "            ('Mittlerer absoluter prozentualer Fehler', 100 * sum(abs(y_residuals / y_true) / len(y_residuals))),\n",
    "        ])\n",
    "    maxlength = max(len(m[0]) for m in metrics)\n",
    "    fmt1 = f'{{:>{maxlength}}} : {{:.4f}}'    \n",
    "    for metric, value in metrics:\n",
    "        print(fmt1.format(metric, value))\n",
    "\n",
    "def singleGraphLayout(ax, ylim, train_df, valid_df):\n",
    "    ax.set_xlim('1990', '2004-6')\n",
    "    ax.set_ylim(*ylim)\n",
    "    ax.set_xlabel('Zeit')\n",
    "    one_month = pd.Timedelta('31 days')\n",
    "    \n",
    "    xtrain = (min(train_df.index), max(train_df.index)-one_month)\n",
    "    xvalid = (min(valid_df.index)+one_month, max(valid_df.index)-one_month)\n",
    "    xtv = xtrain[1]+0.5*(xvalid[0]-xtrain[1])\n",
    "    \n",
    "    ypos = 0.9*ylim[1]+0.1*ylim[0]\n",
    "    ax.add_line(plt.Line2D(xtrain, (ypos, ypos), color='black', linewidth=0.5))\n",
    "    ax.add_line(plt.Line2D(xvalid, (ypos, ypos), color='black', linewidth=0.5))\n",
    "    ax.axvline(x=xtv, ymin=0, ymax=1, color='black', linewidth=0.5)\n",
    "    \n",
    "    ypos = 0.925*ylim[1]+0.075*ylim[0]\n",
    "    ax.text('1995', ypos, 'Training')\n",
    "    ax.text('2002-3', ypos, 'Validation')\n",
    "    \n",
    "def graphLayout(axes, train_df, valid_df):\n",
    "    singleGraphLayout(axes[0], [1300, 2550], train_df, valid_df)\n",
    "    singleGraphLayout(axes[1], [-550, 550], train_df, valid_df)\n",
    "    train_df.plot(y='Ridership', ax=axes[0], color='C0', linewidth=0.75)\n",
    "    valid_df.plot(y='Ridership', ax=axes[0], color='C0', linestyle='dashed', linewidth=0.75)\n",
    "    axes[1].axhline(y=0, xmin=0, xmax=1, color='black', linewidth=0.5)\n",
    "    axes[0].set_xlabel('')\n",
    "    axes[0].set_ylabel('Fahrgäste in tausend')\n",
    "    axes[1].set_ylabel('Vorhersagefehler')\n",
    "    if axes[0].get_legend():\n",
    "        axes[0].get_legend().remove()\n",
    "\n",
    "amtrak_df = pd.read_csv('Daten/Amtrak.csv')\n",
    "amtrak_df['Date'] = pd.to_datetime(amtrak_df.Month, format='%d/%m/%Y')\n",
    "ridership_ts = pd.Series(amtrak_df.Ridership.values, index=amtrak_df.Date, name='Ridership')\n",
    "ridership_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ff6dcd-a224-41d7-b87c-2a708e551c59",
   "metadata": {},
   "source": [
    "Auf die Zeitreihe passen wir ein einfaches lineares Trendmodell an. Dazu nutzen wir in diesem Fall *tsatools*, was uns Werkzeuge spezifisch zur Arbeit mit Zeitreihen bietet. `add_trend` erzeugt aus der Fahrgästezeitreihe ein DataFrame und erweitert es mit dem Parameter `trend='t'` um eine lineare Prädiktorvariable mit einem Wert für jeden Zeitschritt (auch die zeitbezogene Regression arbeitet mit den bekannten Formeln; mit der Kodierung `datetime64` von *Date* können diese nicht viel anfangen, daher die Vereinfachung/Übersetzung). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c42375-a3da-4498-9fae-2db5f49492f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridership_df = tsatools.add_trend(ridership_ts, trend='t')\n",
    "ridership_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71ac8a8-4fca-49a7-8c78-25b142955356",
   "metadata": {},
   "source": [
    "Diesen Datensatz können wir nun als Eingabe für eine *ordinary least squares*-Regression `ols` nutzen. *statsmodels* erlaubt uns, dazu explizit eine Formel mit der Vorhersage `Ridership` in Abhängigkeit vom Prädiktor `trend` zu definieren. `Ridership ~ trend` entspricht dabei $Y_t = \\beta_0 + \\beta_1 t + \\epsilon$. Mit `fit` nimmt das resultierende Modell dann die Anpassung vor. Das Ergebnis stellen wir dar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bf8046-2dd7-49ad-b7d9-e11ef65a1f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridership_lin_reg = smf.ols(formula='Ridership ~ trend', data=ridership_df).fit()\n",
    "ax = ridership_ts.plot()\n",
    "ax.set_xlabel('Zeit')\n",
    "ax.set_ylabel('Fahrgastzahlen in tausend')\n",
    "ax.set_ylim(1300, 2300)\n",
    "ridership_lin_reg.predict(ridership_df).plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345a9c34-b0e9-4065-9c94-542143a8fe3f",
   "metadata": {},
   "source": [
    "Auf dieser Basis können wir auch ein Modell für Vorhersagen bauen. Dazu teilen wir den oben um den Prädiktor erweiterten Datensatz wie gewohnt auf. Das Ergebnis visualisieren wir und die Kennzahlen geben wir auch aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44549b54-69c1-4da5-83c3-6ba67456add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_valid = 36 \n",
    "n_train = len(ridership_ts) - n_valid\n",
    "train_df = ridership_df[:n_train]\n",
    "valid_df = ridership_df[n_train:]\n",
    "\n",
    "ridership_prediction_linear = smf.ols(formula='Ridership ~ trend', data=train_df).fit()\n",
    "predicted_linear = ridership_prediction_linear.predict(valid_df)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(9, 7.5))\n",
    "ridership_prediction_linear.predict(train_df).plot(ax=axes[0], color='C1')\n",
    "ridership_prediction_linear.predict(valid_df).plot(ax=axes[0], color='C1', linestyle='dashed')\n",
    "\n",
    "residual = train_df.Ridership - ridership_prediction_linear.predict(train_df)\n",
    "residual.plot(ax=axes[1], color='C1')\n",
    "residual = valid_df.Ridership - ridership_prediction_linear.predict(valid_df)\n",
    "residual.plot(ax=axes[1], color='C1', linestyle='dashed')\n",
    "graphLayout(axes, train_df, valid_df)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9792f9-b5ac-4080-b204-b84d3d8bae00",
   "metadata": {},
   "source": [
    "Für das Ergebnis lassen wir uns eine Auswertung ausgeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528369e0-15ec-45a5-8068-9df36457356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ridership_prediction_linear.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524979b3-16fd-4a8c-8d11-4678348160ae",
   "metadata": {},
   "source": [
    "Der *Intercept* ist der Wert der Konstante $\\beta_0$, *trend* der Koeffizient $\\beta_1$. An ihren ggf. akzeptablen statistischen Kennzahlen sehen wir hier, dass die Betrachtung der Form des zeitlichen Verlaufs erforderlich ist, nicht nur der reinen Zahlen, denn offensichtlich gibt es hier keinen linearen Zusammenhang. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fccd092-9fc6-48d0-8232-78fa37f9d989",
   "metadata": {},
   "source": [
    "Also versuchen wir es als nächstes mit einem *exponentiellem Trend*. Praktisch nutzen wir hier die Umformung von $Y_t = ce^{\\beta_1 t + \\epsilon}$ zu $\\log Y_t = \\beta_0 + \\beta_1 t + \\epsilon$. Bei der Auswertung und Darstellung müssen wir dann aber beachten, die Trainingsdaten und Vorhersagen auf die ursprüngliche Skala abzubilden. Dazu wenden wir hier die Exponentialfunktion als $\\lambda$ auf die entsprechenden Werte an. \n",
    "\n",
    "Im Vergleich stellt sich dann ein sehr ähnliches Ergebnis wie im linearen Modell dar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d4ad49-1dee-462a-b54b-f789ea54e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridership_prediction_expo = smf.ols(formula='np.log(Ridership) ~ trend', data=train_df).fit()\n",
    "predicted_expo = ridership_prediction_expo.predict(valid_df).apply(lambda row: np.exp(row))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(9, 3.75))\n",
    "train_df.plot(y='Ridership', ax=ax, color='C0', linewidth=0.75)\n",
    "valid_df.plot(y='Ridership', ax=ax, color='C0', linestyle='dashed', linewidth=0.75)\n",
    "singleGraphLayout(ax, [1300, 2600], train_df, valid_df)\n",
    "ridership_prediction_linear.predict(train_df).plot(color='C1')\n",
    "ridership_prediction_linear.predict(valid_df).plot(color='C1', linestyle='dashed')\n",
    "ridership_prediction_expo.predict(train_df).apply(lambda row: np.exp(row)).plot(color='C2')\n",
    "ridership_prediction_expo.predict(valid_df).apply(lambda row: np.exp(row)).plot(color='C2', linestyle='dashed')\n",
    "ax.get_legend().remove()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c5e74d-0cc0-4089-8a5e-08d07da342e2",
   "metadata": {},
   "source": [
    "Passen wir als nächstes einen *polynomialen Trend* an. Dazu fügen wir einen weiteren Prädiktor $t^2$ in die Formel ein. Dieser quadratische Zusammenhang ist hier nahe liegend, da der Verlauf der Daten \"U-förmig\" wirkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab37f8cc-bce6-49ae-98cc-344b7249e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridership_prediction_poly = smf.ols(formula='Ridership ~ trend + np.square(trend)', data=train_df).fit()\n",
    "predicted_poly = ridership_prediction_poly.predict(valid_df)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(9, 7.5))\n",
    "ridership_prediction_poly.predict(train_df).plot(ax=axes[0], color='C1')\n",
    "ridership_prediction_poly.predict(valid_df).plot(ax=axes[0], color='C1', linestyle='dashed')\n",
    "\n",
    "residual = train_df.Ridership - ridership_prediction_poly.predict(train_df)\n",
    "residual.plot(ax=axes[1], color='C1')\n",
    "residual = valid_df.Ridership - ridership_prediction_poly.predict(valid_df)\n",
    "residual.plot(ax=axes[1], color='C1', linestyle='dashed')\n",
    "graphLayout(axes, train_df, valid_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b7aed7-87e8-48e4-ae3c-6496d8279157",
   "metadata": {},
   "source": [
    "Das Ergebnis wirkt nun passender als bei den bisherigen Ansätzen oben, da die Residuen keinen erkennbaren Trend mehr aufweisen. Diese Komponente haben wir also erfasst und wenden uns der *Saisonalität* zu.\n",
    "\n",
    "Allgemein erfordert das eine neue kategorische Variable, die jeden Wert der Zeitreihe einer Saison zuordnet. Die Kategorien werden dann auf Dummy-Variablen abgebildet, die als Prädiktoren in das Modell eingehen. Im hier gegebenen Fall ist das der *Monat*, den wir dem Datensatz hinzufügen. Zunächst - wir wollen eine Vorhersage nur auf Basis der Saisonalität - ist der Trend dabei als konstant angenommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b47db09-13bb-4e68-9011-e740ef292bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridership_df = tsatools.add_trend(ridership_ts, trend='c')\n",
    "ridership_df['Month'] = ridership_df.index.month\n",
    "ridership_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4160761-3133-4731-b155-ba70df509706",
   "metadata": {},
   "source": [
    "Durch die Angabe `C(Month)` nimmt *statsmodels* uns die Umwandlung in Dummies ab. Auf dieser Basis machen wir dann wie gewohnt unsere Vorhersage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b55b75-31f6-4768-b8ca-098cf30bad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = ridership_df[:n_train]\n",
    "valid_df = ridership_df[n_train:]\n",
    "ridership_prediction_season = smf.ols(formula='Ridership ~ C(Month)', data=train_df).fit()\n",
    "predicted_season = ridership_prediction_season.predict(valid_df)\n",
    "print(ridership_prediction_season.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f384ed4-ebcf-4b18-90d7-a678887254b2",
   "metadata": {},
   "source": [
    "Das Ergebnis stellen wir grafisch dar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb6799-1feb-45e5-bcc3-de453beccd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(9, 7.5))\n",
    "ridership_prediction_season.predict(train_df).plot(ax=axes[0], color='C1')\n",
    "ridership_prediction_season.predict(valid_df).plot(ax=axes[0], color='C1', linestyle='dashed')\n",
    "\n",
    "residual = train_df.Ridership - ridership_prediction_season.predict(train_df)\n",
    "residual.plot(ax=axes[1], color='C1')\n",
    "residual = valid_df.Ridership - ridership_prediction_season.predict(valid_df)\n",
    "residual.plot(ax=axes[1], color='C1', linestyle='dashed')\n",
    "graphLayout(axes, train_df, valid_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ec419a-812c-4358-8ac8-613a43638234",
   "metadata": {},
   "source": [
    "Das Modell erfasst die Saisonalität passend, die Residuen weisen aber wieder einen Trend auf. Also fügen wir den quadratischen Trend hinzu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cefb32-459d-4de3-a79f-29499c0d2617",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridership_df = tsatools.add_trend(ridership_ts, trend='ct')\n",
    "ridership_df['Month'] = ridership_df.index.month\n",
    "train_df = ridership_df[:n_train]\n",
    "valid_df = ridership_df[n_train:]\n",
    "ridership_prediction_trend_season = smf.ols(formula='Ridership ~ trend + np.square(trend) + C(Month)', data=train_df).fit()\n",
    "predicted_trend_season = ridership_prediction_trend_season.predict(valid_df)\n",
    "print(ridership_prediction_trend_season.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cf3878-bb0a-4ded-bca8-6907231e7d72",
   "metadata": {},
   "source": [
    "Die grafische Darstellung bietet den Eindruck eines stark verbesserten Modells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965eadae-d684-4d99-b76d-4f934246298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(9, 7.5))\n",
    "ridership_prediction_trend_season.predict(train_df).plot(ax=axes[0], color='C1')\n",
    "ridership_prediction_trend_season.predict(valid_df).plot(ax=axes[0], color='C1', linestyle='dashed')\n",
    "\n",
    "residual_train = train_df.Ridership - ridership_prediction_trend_season.predict(train_df)\n",
    "residual_train.plot(ax=axes[1], color='C1')\n",
    "residual_valid = valid_df.Ridership - ridership_prediction_trend_season.predict(valid_df)\n",
    "residual_valid.plot(ax=axes[1], color='C1', linestyle='dashed')\n",
    "graphLayout(axes, train_df, valid_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24acb83-e217-4e02-8656-a09802edcff2",
   "metadata": {},
   "source": [
    "Auch eine Betrachtung der Kennzahlen der Vorhersagen gegenüber dem Validierungsdatensatz im Vergleich bestätigt diesen Eindruck:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983eb4a7-2cbe-4477-99f6-44fba0b544a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lineares Modell')\n",
    "regressionSummary(valid_df.Ridership, predicted_linear)\n",
    "print('')\n",
    "print('Exponentielles Modell')\n",
    "regressionSummary(valid_df.Ridership, predicted_expo)\n",
    "print('')\n",
    "print('Quadratisches Modell')\n",
    "regressionSummary(valid_df.Ridership, predicted_poly)\n",
    "print('')\n",
    "print('Additiv-saisonales Modell')\n",
    "regressionSummary(valid_df.Ridership, predicted_season)\n",
    "print('')\n",
    "print('Quadratisches Modell mit Saisonalität')\n",
    "regressionSummary(valid_df.Ridership, predicted_trend_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339b8f7d-3a2e-4842-992b-168915e7bb77",
   "metadata": {},
   "source": [
    "## Aufgabe\n",
    "\n",
    "Der Datensatz *a10.csv* enthält die monatlichen Absätze eines Medikamentes gegen Diabetes. Implementieren Sie ein geeignetes Modell zur Prädiktion der Absätze. Passen Sie zu diesem Zweck ggf. auch die Hilfsfunktionen zur Darstellung an."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e277f9-82db-4dc0-8195-99aca140a50f",
   "metadata": {},
   "source": [
    "## Autokorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e43d29f-aa5e-4579-9494-e71cbaf26d6b",
   "metadata": {},
   "source": [
    "Zur Illustration von Autokorrelation am Beispiel der Fahrgastdaten generieren wir zunächst die verzögerten Reihen bis *lag-4* für die ersten 24 Monate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f245e77d-ae34-4c8a-8fe2-e072de47a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lagged_riderships_df = pd.DataFrame()\n",
    "for lag in range(0, 5):\n",
    "    lagged_riderships_df[f'Lag {lag}'] = train_df['1991-01-01':'1992-12-01']['Ridership'].shift(lag)\n",
    "\n",
    "lagged_riderships_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548a5dba-f6d7-4cb8-b0a7-c9c6ad97cc3c",
   "metadata": {},
   "source": [
    "Die Fahrgastzahlen der ursprünglichen Zeitreihe treten in den *Lag n* jeweils *n* Monate später auf. Nun stellt sich die Frage nach der Korrelation zwischen der ursprünglichen Zeitreihe und ihren verzögerten Varianten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019c3ec1-d1da-47aa-a325-66681a5436e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lag in range(0, 5):\n",
    "    print('Autokorrelation Lag {} = {}'.format(lag, train_df['1991-01-01':'1992-12-01'].Ridership.autocorr(lag=lag)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941f8105-7937-48f8-a1b3-eb0f469f1b56",
   "metadata": {},
   "source": [
    "Wir sehen schwankende Werte und einen eher niedrigen Wert für *Lag 1*. Schauen wir uns also die *Autokorrelationsfunktion* ACF der Zeitreihe an, die uns *statsmodels* für den betrachteten Zeitraum liefert und auch passend darstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a705f5-6866-4cef-86ee-f48d1e75cdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsaplots.plot_acf(train_df['1991-01-01':'1992-12-01'].Ridership)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a883fff-71e8-4d26-938d-c389843f6018",
   "metadata": {},
   "source": [
    "Hier sehen wir die stärkste Autokorrelation bei Lag 6. Sie ist negativ und liegt außerhalb des 95%-Konfidenzintervalls, was auf ein verbesserungsfähiges Modell hinweist. Außerdem erkennen wir einen halbjährliche Wechsel zwischen niedrigem und hohem Fahrgastaufkommen, was wir auch schon oben in der Zeitreihe sehen konnten.\n",
    "\n",
    "Es kann hilfreich sein, auch die Autokorrelation der Residuen zu betrachten. Eine angemessene Modellierung der Saisonalitäten sollte die Autokorrelation der Residuen unterdrücken. Stellen wir das für unser letztes (und bestes) Modell mit Trend und Saisonalität dar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1240d0-9b0d-4fed-9c43-21ff2633cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsaplots.plot_acf(residual_train['1991-01-01':'1992-12-01'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced872dd-54ff-47be-86f8-5c454a61c586",
   "metadata": {},
   "source": [
    "Hier sehen wir Autokorrelationen und eine Saisonalität, die wir nutzen können, um Vorhersagefehler vorherzusagen. Dazu passen wir die Residuen an ein vorhandenes *ARIMA*-Modell an. Es ist hier ausreichend, einen Lag von 1 anzunehmen (`order=(1,...)`), da sich hier die unmittelbaren Nachbarn beinflussen und diese Beziehung sich auch auf die folgenden Werte auswirkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a02af8-b1a3-459c-a230-86194918cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_residuals_arima = ARIMA(ridership_prediction_trend_season.resid, order=(1,0,0), freq='MS', trend='ct').fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a9db9c-c132-440a-9108-e1f7ab38db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = ridership_prediction_trend_season.resid.plot(figsize=(9,4))\n",
    "train_residuals_arima.fittedvalues.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb3df22-60e5-4683-8b46-cfbca3ce79bd",
   "metadata": {},
   "source": [
    "Die vorhergesagten Fehler sind nahe an den tatsächlichen Fehlern der Zeitreihe. Auch zeigt sich, dass nur noch eine vernachlässigbare Autokorrelation zwischen den Residuen der Fehler verbleibt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d8a7eb-7a0d-42ba-8127-3b6bb0982576",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsaplots.plot_acf(ridership_prediction_trend_season.resid-train_residuals_arima.fittedvalues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a50c5b-9bce-44b5-8fda-4a2d752808bf",
   "metadata": {},
   "source": [
    "Generieren wir eine Vorhersage des Fehlers für den April 2001 und nutzen sie zur Korrektur unserer bisherigen Vorhersage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c69356-0e06-4ba3-a6e5-3873668ac28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tatsächlicher Wert = {}'.format(valid_df.loc['2001-04-01'].Ridership))\n",
    "print('Vorhergesagter Wert = {}'.format(predicted_trend_season.loc['2001-04-01']))\n",
    "print('Fehler = {}'.format(valid_df.loc['2001-04-01'].Ridership - predicted_trend_season.loc['2001-04-01']))\n",
    "print('Vorhergesagter Fehler = {}'.format(train_residuals_arima.forecast(1).loc['2001-04-01']))\n",
    "print('Korrigierte Vorhersage = {}'.format(predicted_trend_season.loc['2001-04-01']+train_residuals_arima.forecast(1).loc['2001-04-01']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80e872a-2256-4af7-bfb5-95b9812d26b4",
   "metadata": {},
   "source": [
    "Durch die spezifischen Eigenschaften der AR-Modelle eignen sie sich eher zur kurzfristigen Vorhersage der nächsten *k* Perioden. Danach greifen sie auf frühere Vorhersagen zurück."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
