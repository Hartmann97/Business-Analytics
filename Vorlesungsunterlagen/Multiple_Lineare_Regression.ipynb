{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daa76cea-de4b-4371-bd27-8c9ac072c352",
   "metadata": {},
   "source": [
    "#### Business Analytics FHDW 2025\n",
    "# Vorhersagen von Eigenschaften durch multiple lineare Regression\n",
    "## am Beispiel von Gebrauchtwagenpreisen\n",
    "\n",
    "Im Beispielszenario (wieder ein modifiziertes Beispiel aus Shmueli et al.) nimmt ein Autohandel gebrauchte Fahrzeuge in Zahlung. Er möchte natürlich wissen, wie viel das Auto potentiell noch wert ist. \n",
    "\n",
    "Zunächst importieren wir uns eine Reihe von Hilfsmitteln. Außerdem bauen wir uns unsere eigene kleine Funktion zur Zusammenfassung der Regressionsergebnisse. Falls *dmba* noch nicht installiert ist, holen Sie das mit dem Package Manager (*\"PIP Installs Packages\"*) von Python in der Anaconda Shell oder mit der Umleitung einer Zeile auf die Shell durch `!` nach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9e1aa9-fa6c-4033-ae2c-7aa38cbfe832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.executable adressiert die Python-Installation von Jupyter \n",
    "! {sys.executable} -m pip install dmba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09029c1d-5ab1-4d70-92d5-2da03ddc2106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.formula.api as sm\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from dmba import adjusted_r2_score, AIC_score, BIC_score\n",
    "\n",
    "def regressionSummary(y_true, y_predicted):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_predicted = np.asarray(y_predicted)\n",
    "    y_residuals = y_true - y_predicted\n",
    "    metrics = [\n",
    "        ('Summe Abweichungen', sum(y_residuals)),\n",
    "        ('Summe absolute Abweichungen', sum(abs(y_residuals))),\n",
    "        ('Mittlerer Fehler', sum(y_residuals) / len(y_residuals)),\n",
    "        ('Mittlerer absoluter Fehler', sum(abs(y_residuals)) / len(y_residuals)),\n",
    "        ('Wurzel des durchschnittlichen Fehlerquadrats', math.sqrt(mean_squared_error(y_true, y_predicted)))\n",
    "    ]\n",
    "    if all(yt != 0 for yt in y_true):\n",
    "        metrics.extend([\n",
    "            ('Mittlerer prozentualer Fehler', 100 * sum(y_residuals / y_true) / len(y_residuals)),\n",
    "            ('Mittlerer absoluter prozentualer Fehler', 100 * sum(abs(y_residuals / y_true) / len(y_residuals))),\n",
    "        ])\n",
    "    maxlength = max(len(m[0]) for m in metrics)\n",
    "    fmt1 = f'{{:>{maxlength}}} : {{:.4f}}'\n",
    "    print('\\nRegressionskennzahlen\\n')\n",
    "    for metric, value in metrics:\n",
    "        print(fmt1.format(metric, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b87bcb7-910a-4eaa-9209-74e9bf48ca8e",
   "metadata": {},
   "source": [
    "Wir lesen unsere Daten ein, reduzieren die auf die ersten 1000 Zeilen und wählen die für uns interessanten Spalten als Prädiktoren aus. Abhängige Zielvariable ist der Preis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141fd80b-10ff-4ace-8ef4-525f82cc8e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df = pd.read_csv('Daten/ToyotaCorolla.csv')\n",
    "car_df = car_df.iloc[0:1000]\n",
    "\n",
    "predictors = ['age_08_04', \n",
    "              'km', \n",
    "              'fuel_type', \n",
    "              'hp', \n",
    "              'met_color', \n",
    "              'automatic', \n",
    "              'cc', \n",
    "              'doors', \n",
    "              'quarterly_tax', \n",
    "              'weight']\n",
    "outcome = 'price'\n",
    "\n",
    "car_df[predictors]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a477d516-0f6b-4b78-b858-3bdc5d60481c",
   "metadata": {},
   "source": [
    "Kategorische Variablen wandeln wir in numerische, binäre Dummies um. Das betrifft im Falle unserer gewählten Prädiktoren die Treibstoffart. `drop_first=True` sorgt dafür, dass die erste resultierende Dummy-Variable verworfen wird, da sie durch ihre binären Werte vollständig mit den verknüpften bzw. weiteren aus der ursprünglichen kategorischen Variable generierten Dummies korreliert. Bzw. ist sie demnach schlicht redundant (wo die verbleibenden Dummies alle 0 sind, wäre der entfernte 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba1b9b-901e-4781-a13f-4ddeaa80dd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(car_df.fuel_type.unique())\n",
    "X = pd.get_dummies(car_df[predictors], drop_first=True)\n",
    "y = car_df[outcome]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b625d98-c9c8-4604-8068-70e13e09a694",
   "metadata": {},
   "source": [
    "Mit `lmplot` aus *seaborn* können wir *scatterplots* mit einer Regressionsgeraden (`order=1`) generieren, die uns einen ersten Eindruck über die Verteilungen einzelner Prädiktoren liefern (der Bereich um die Gerade ist ein Konfidenzintervall). Wir setzen den Preis jeweils in Abhängigkeit von Alter, Kilometerstand und PS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f95a9-978d-4986-b5bc-511576f21bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x =\"age_08_04\", y =\"price\", data = car_df, order = 1)\n",
    "sns.lmplot(x =\"km\", y =\"price\", data = car_df, order = 1)\n",
    "sns.lmplot(x =\"hp\", y =\"price\", data = car_df, order = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18a177c-1233-45d3-a802-32274ccb6b0c",
   "metadata": {},
   "source": [
    "Da wir eine bestmögliche *Vorhersage* erzielen möchten, teilen wir den Datensatz in eine Untermenge von 60% für Training und eine für Test bzw. Validierung von 40% auf. Die Datenpunkte wählt die Funktion `train_test_split` zufällig aus. Damit das Ergebnis trotzdem reproduzierbar bleibt, geben wir einen *seed* von 1 im Parameter `random_state` an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29701f83-b73d-42a7-8bf4-03de53db634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d7df9a-8e63-4c0f-9de9-60cdc48eb8a7",
   "metadata": {},
   "source": [
    "Auf den Trainingsdatensätzen können wir nun die Regression durchführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126e4fb6-61f6-46e3-ae3e-2dc4d771211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_lr = LinearRegression()\n",
    "car_lr.fit(train_X, train_y)\n",
    "\n",
    "print(pd.DataFrame({'Prediktor': X.columns, 'Koeffizient': car_lr.coef_}))\n",
    "regressionSummary(train_y, car_lr.predict(train_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6799a0be-a9ac-4064-a990-f077e2327509",
   "metadata": {},
   "source": [
    "Das ist die zu erwartende Anpassung an den *Trainings*datensatz. Um die Prognosequalität unseres generierten Modells zu überprüfen, sagen wir die Preise der Fahrzeuge aus unserem Validierungsdatensatz voraus. Die Prädiktionen gleichen wir mit den echten Werten ab, indem wir die Differenzen bzw. Residuen ermitteln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa6f144-5d7c-4a82-b628-9ad576a571e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_lr_prediction = car_lr.predict(valid_X)\n",
    "residuals = valid_y-car_lr_prediction\n",
    "prediction_results = pd.DataFrame({'Vorhersage': car_lr_prediction, 'Tatsächlich': valid_y, 'Residuum': residuals})\n",
    "print(prediction_results.head(20))\n",
    "regressionSummary(valid_y, car_lr_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b32201f-1ced-4930-aa18-f86189ffd60d",
   "metadata": {},
   "source": [
    "Die Bewertung der Resultate und ihre Qualität ist vom jeweiligen Anwendungsfall und seinen konkreten Anforderungen abhängig: Ist die Vorhersage genau genug? \n",
    "\n",
    "Daher noch einen Blick auf die Plausibilität des Modells, d. h. sind die Voraussetzungen überhaupt erfüllt? Ein *Tukey-Anscombe*-Diagramm aus den Prädiktionen und Residuen zeigt folgendes Bild. Erinnern sich sich an DAML - wie interpretieren Sie die Ergebnisse (wir möchten hier möglichst *homoskedastische* Daten)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622ed017-92a5-407f-a05e-48302663295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_plot = prediction_results.plot.scatter(x=\"Vorhersage\", y=\"Residuum\")\n",
    "ta_plot.plot([0, 25000], [0, 0], color='red') # [Start x, Ende x], [Start y, Ende y]\n",
    "scedasticity = pd.DataFrame({'Alter': valid_X[\"age_08_04\"], 'km': valid_X[\"km\"], 'Residuum': residuals})\n",
    "scedasticity.plot.scatter(x=\"Alter\", y=\"Residuum\")\n",
    "scedasticity.plot.scatter(x=\"km\", y=\"Residuum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da18c733-1514-4f65-bbca-7598d6ccc19b",
   "metadata": {},
   "source": [
    "Die Verteilung der Residuen zeigt folgende Form - Interpretation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05c227c-8bf9-4d58-b3d8-118ae06c4786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'Residuen': residuals}).hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a5fbd1-eacc-4ab9-a860-59a64b1b0e65",
   "metadata": {},
   "source": [
    "## Aufgabe\n",
    "\n",
    "1. Untersuchen Sie den Gebrauchtwagen-Datensatz auf redundante Variablen. Wenn Sie Variablen entfernen, versuchen Sie das sowohl aus dem Domänenkontext, als auch abstrakt anhand der Zahlen zu begründen.\n",
    "\n",
    "2. Führen Sie mit dem reduzierten Datensatz eine Regression zur Vorhersage des Preises durch. Vergleichen Sie die Performance Ihres reduzierten Modells mit der des Modells mit dem vollen Umfang."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62de2234-8680-41a3-ab4a-4cb6903a0615",
   "metadata": {},
   "source": [
    "## Variablenauswahl für die lineare Regression\n",
    "\n",
    "Die Reduzierung der Prädiktoren wie in der Übung ist mühsam und - spätestens bei hochdimensionalen Modellen - fehleranfällig. Da wir uns des Rechners bedienen, gibt es aber (neben PCA) weitere Möglichkeiten der Automatisierung.\n",
    "\n",
    "Es gibt dazu eine Reihe von Kriterien zur Evaluierung und zum Vergleich von Modellen auf Grundlage von Metriken, die sich aus den Trainingsdaten berechnen lassen:\n",
    "\n",
    "*Angepasstes* $R^2$ als $R^2_{adj}=1-\\frac{n-1}{n-p-1}(1-R^2)$ mit $R^2=\\frac{\\sum{(\\hat{y}_i-\\overline{y})^2}}{\\sum{(y_i-\\overline{y})^2}}$\n",
    "\n",
    "$R^2$ ist der Anteil der erklärten Variabilität in einem Modell. Die Anpassung nach $R^2_{adj}$ sorgt dafür, dass eine höhere Anzahl von Prädiktoren bestraft wird. Höhere Werte bedeuten eine bessere Anpassung des Modells.\n",
    "\n",
    "*Akaike Information Criterion* $AIC=n\\ln(SSE/n)+n(1+\\ln(2\\pi))+2(p+1)$\n",
    "\n",
    "*Bayesian Information Criterion* $BIC=n\\ln(SSE/n)+n(1+\\ln(2\\pi))+\\ln(n)(p+1)$\n",
    "\n",
    "$p$ ist die Anzahl der Prädiktoren, $n$ die Anzahl der Datensätze, $SSE=\\sum_{i=1}^{n}{e^2_i}$ die Summe der Fehlerquadrate.\n",
    "\n",
    "$AIC$ und $BIC$ schätzen den informationstheoretischen Vorhersagefehler eines Modells und bestrafen dabei auch höhere Parameteranzahlen. Niedrigere Werte bedeuten bessere Modelle. \n",
    "\n",
    "Die folgenden Implementierungen finden wir bei Shmueli et al. bzw. dem begleitenden Repo github.com/gedeck/dmba/blob/master/src/dmba/. Die Quellen sind hier teilweise leicht modifiziert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7553ef7b-ec3b-4d43-8155-f8546b3a767b",
   "metadata": {},
   "source": [
    "### Erschöpfende Suche\n",
    "\n",
    "Ein Ansatz \"roher Gewalt\" (*brute force*) besteht in der Auswertung aller möglichen Untermengen aus Prädiktoren. Für jede Untermenge wird die Modellperformance geprüft, die mit dem besten Ergebnis wird für die Vorhersagen genutzt.\n",
    "\n",
    "Die nachfolgende Funktion untersucht also diesen Raum aller möglichen Lösungen und gibt für jede Anzahl von Prädiktoren die Untermenge mit dem besten $R^2_{adj}$-Wert zurück."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ebba6b-ba9c-4142-8bd3-254cf180d80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def train_model_exhaustive(variables):\n",
    "    model = LinearRegression()\n",
    "    model.fit(train_X[list(variables)], train_y)\n",
    "    return model\n",
    "\n",
    "def score_model_exhaustive(model, variables):\n",
    "    pred_y = model.predict(train_X[list(variables)])\n",
    "    return -adjusted_r2_score(train_y, pred_y, model)\n",
    "\n",
    "def exhaustive_search(variables, train_model, score_model):    \n",
    "    \"\"\"\n",
    "    Input:\n",
    "        variables: complete list of variables to consider in model building\n",
    "        train_model: function that returns a fitted model for a given set of variables\n",
    "        score_model: function that returns the score of a model; better models have lower scores\n",
    "    Returns:\n",
    "        List of best subset models for increasing number of variables\n",
    "    \"\"\"\n",
    "    # create models of increasing size and determine the best models in each case\n",
    "    result = []\n",
    "    for nvariables in range(1, len(variables) + 1):\n",
    "        best_subset = None\n",
    "        best_score = None\n",
    "        best_model = None\n",
    "        for subset in itertools.combinations(variables, nvariables):\n",
    "            subset = list(subset)\n",
    "            subset_model = train_model(subset)\n",
    "            subset_score = score_model(subset_model, subset)\n",
    "            if best_subset is None or best_score > subset_score:\n",
    "                best_subset = subset\n",
    "                best_score = subset_score\n",
    "                best_model = subset_model\n",
    "        result.append({\n",
    "            'n': nvariables,\n",
    "            'variables': best_subset,\n",
    "            'score': best_score,\n",
    "            'model': best_model,\n",
    "        })\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c906c0-dd90-48d8-93cd-14da7e587e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_variables = train_X.columns\n",
    "results = exhaustive_search(all_variables, train_model_exhaustive, score_model_exhaustive)\n",
    "\n",
    "data = []\n",
    "for result in results:\n",
    "    model = result['model']\n",
    "    variables = list(result['variables'])\n",
    "    aic = AIC_score(train_y, model.predict(train_X[variables]), model)\n",
    "    d = {'n':result['n'], 'r2adj':-result['score'], 'AIC':aic}\n",
    "    d.update({var: var in result['variables'] for var in all_variables})\n",
    "    data.append(d)\n",
    "\n",
    "pd.DataFrame(data, columns=('n', 'r2adj', 'AIC') + tuple(sorted(all_variables)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50639409-717c-40b3-8e4e-1edc053eaedf",
   "metadata": {},
   "source": [
    "### Auswahl von Untermengen\n",
    "\n",
    "Bei einer großen Anzahl an Prädiktoren stößt die erschöpfende Suche auch bei leistungsfähigen Infrastrukturen irgendwann an Grenzen. Ein Kompromiss, der entsprechend nicht immer zum optimalen Ergebnis führt, besteht in der Untersuchung nur von Teilmengen des gesamten Lösungsraums. Diese Teilmengen werden iterativ nach unterschiedlichen Ansätzen gebildet.\n",
    "\n",
    "Die **Forward Selection** startet mit einer leeren Prädiktorenmenge und fügt in jedem Schritt einen Prädiktor hinzu. Es wird der ausgewählt, der - zusätzlich zu den schon vorhandenen - den größten Beitrag zur Performance des Modells leistet. Die Iteration hält an, wenn der zusätzliche Beitrag nicht mehr statistisch signifikant ist. Der Algorithmus berücksichtigt dabei entsprechend nicht alle Kombinationen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911aac4a-f3fa-4961-a304-572eee7da7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_forward_selection(variables):\n",
    "    if len(variables) == 0:\n",
    "        return None\n",
    "    model = LinearRegression()\n",
    "    model.fit(train_X[variables], train_y)\n",
    "    return model\n",
    "\n",
    "def score_model_forward_selection(model, variables):\n",
    "    if len(variables) == 0:\n",
    "        return AIC_score(train_y, [train_y.mean()]*len(train_y), model, df=1)\n",
    "    return AIC_score(train_y, model.predict(train_X[variables]), model)\n",
    "\n",
    "def forward_selection(variables, train_model, score_model, verbose=True):\n",
    "    \"\"\" \n",
    "    Input:\n",
    "        variables: complete list of variables to consider in model building\n",
    "        train_model: function that returns a fitted model for a given set of variables\n",
    "        score_model: function that returns the score of a model; better models have lower scores\n",
    "    Returns:\n",
    "        (best_model, best_variables)\n",
    "    \"\"\"\n",
    "    # we start with a model that contains no variables\n",
    "    best_variables = []\n",
    "    best_model = train_model(best_variables)\n",
    "    best_score = score_model(best_model, best_variables)\n",
    "    if verbose:\n",
    "        print('Variables: ' + ', '.join(variables))\n",
    "        print(f'Start: score={best_score:.2f}, constant')\n",
    "    while True:\n",
    "        step = [(best_score, None, best_model)]\n",
    "        for addVar in variables:\n",
    "            if addVar in best_variables:\n",
    "                continue\n",
    "            step_var = list(best_variables)\n",
    "            step_var.append(addVar)\n",
    "            step_model = train_model(step_var)\n",
    "            step_score = score_model(step_model, step_var)\n",
    "            step.append((step_score, addVar, step_model))\n",
    "        step.sort(key=lambda x: x[0])\n",
    "\n",
    "        # the first entry in step is now the model that improved most\n",
    "        best_score, added_step, best_model = step[0]\n",
    "        if verbose:\n",
    "            print(f'Step: score={best_score:.2f}, add {added_step}')\n",
    "        if added_step is None:\n",
    "            # stop here, as adding more variables is detrimental to performance\n",
    "            break\n",
    "        best_variables.append(added_step)\n",
    "    return best_model, best_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac35e97-67a6-4253-8111-3463e4727bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, best_variables = forward_selection(train_X.columns, \n",
    "                                               train_model_forward_selection,\n",
    "                                               score_model_forward_selection,\n",
    "                                               verbose=True)\n",
    "print(best_variables)\n",
    "regressionSummary(valid_y, best_model.predict(valid_X[best_variables]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3713faae-f194-442a-b1cf-29ebbfea6880",
   "metadata": {},
   "source": [
    "Die **Backward Elimination** startet mit der Menge aller Prädiktoren und reduziert in darauf folgenden Schritten die Menge jeweils um den Prädiktor mit dem geringsten Nutzen für die Performance des Modells gemäß statistischer Signifikanz. Der Algorithmus stoppt, wenn alle in der Untermenge enthaltenen Prädiktoren einen statistisch signifikanten Beitrag leisten. Nachteilig ist hier u. a., dass die ersten Modelle mit allen bzw. vielen Prädiktoren sehr aufwändig zu prüfen sein können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db8be80-e6ba-4beb-acf2-696d750c3a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_backward_elimination(variables):\n",
    "    model = LinearRegression()\n",
    "    model.fit(train_X[variables], train_y)\n",
    "    return model\n",
    "\n",
    "def score_model_backward_elimination(model, variables):\n",
    "    return AIC_score(train_y, model.predict(train_X[variables]), model)  \n",
    "\n",
    "def backward_elimination(variables, train_model, score_model, verbose=False):\n",
    "    \"\"\" \n",
    "    Input:\n",
    "        variables: complete list of variables to consider in model building\n",
    "        train_model: function that returns a fitted model for a given set of variables\n",
    "        score_model: function that returns the score of a model; better models have lower scores\n",
    "    Returns:\n",
    "        (best_model, best_variables)\n",
    "    \"\"\"\n",
    "    # we start with a model that contains all variables\n",
    "    best_variables = list(variables)\n",
    "    best_model = train_model(best_variables)\n",
    "    best_score = score_model(best_model, best_variables)\n",
    "    if verbose:\n",
    "        print('Variables: ' + ', '.join(variables))\n",
    "        print(f'Start: score={best_score:.2f}')\n",
    "\n",
    "    while len(best_variables) > 1:\n",
    "        step = [(best_score, None, best_model)]\n",
    "        for removeVar in best_variables:\n",
    "            step_var = list(best_variables)\n",
    "            step_var.remove(removeVar)\n",
    "            step_model = train_model(step_var)\n",
    "            step_score = score_model(step_model, step_var)\n",
    "            step.append((step_score, removeVar, step_model))\n",
    "\n",
    "        # sort by ascending score\n",
    "        step.sort(key=lambda x: x[0])\n",
    "\n",
    "        # the first entry is the model with the lowest score\n",
    "        best_score, removed_step, best_model = step[0]\n",
    "        if verbose:\n",
    "            print(f'Step: score={best_score:.2f}, remove {removed_step}')\n",
    "        if removed_step is None:\n",
    "            # step here, as removing more variables is detrimental to performance\n",
    "            break\n",
    "        best_variables.remove(removed_step)\n",
    "    return best_model, best_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e0b56-76b9-4373-985a-c36dc914edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_variables = train_X.columns\n",
    "best_model, best_variables = backward_elimination(all_variables, \n",
    "                                                  train_model_backward_elimination, \n",
    "                                                  score_model_backward_elimination,\n",
    "                                                  verbose=True)\n",
    "\n",
    "print(best_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d5aa69-5fb5-4b9c-a1de-cc33c719564b",
   "metadata": {},
   "source": [
    "Die **Stepwise Selection** arbeitet wie die *Forward Selection* oben, schließt aber in jedem Schritt wie die *Backward Elimination* Prädiktoren aus, die keinen statistisch signifikanten Beitrag leisten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f55edfc-68fa-4e2a-b4ac-b7dc153a5dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise_selection(variables, train_model, score_model, direction='both', verbose=True):\n",
    "    \"\"\" \n",
    "    Input:\n",
    "        variables: complete list of variables to consider in model building\n",
    "        train_model: function that returns a fitted model for a given set of variables\n",
    "        score_model: function that returns the score of a model; better models have lower scores\n",
    "        direction: use it to limit stepwise selection to either 'forward' or 'backward'\n",
    "    Returns:\n",
    "        (best_model, best_variables)\n",
    "    \"\"\"\n",
    "    FORWARD = 'forward'\n",
    "    BACKWARD = 'backward'\n",
    "    directions = [FORWARD, BACKWARD]\n",
    "    if direction.lower() == FORWARD:\n",
    "        directions = [FORWARD]\n",
    "    if direction.lower() == BACKWARD:\n",
    "        directions = [BACKWARD]\n",
    "\n",
    "    # we start with a model that contains no variables\n",
    "    best_variables = [] if 'forward' in directions else list(variables)\n",
    "    best_model = train_model(best_variables)\n",
    "    best_score = score_model(best_model, best_variables)\n",
    "    if verbose:\n",
    "        print('Variables: ' + ', '.join(variables))\n",
    "        print(f'Start: score={best_score:.2f}, constant')\n",
    "\n",
    "    while True:\n",
    "        step = [(best_score, None, best_model, 'unchanged')]\n",
    "        if FORWARD in directions:\n",
    "            for variable in variables:\n",
    "                if variable in best_variables:\n",
    "                    continue\n",
    "                step_var = list(best_variables)\n",
    "                step_var.append(variable)\n",
    "                step_model = train_model(step_var)\n",
    "                step_score = score_model(step_model, step_var)\n",
    "                step.append((step_score, variable, step_model, 'add'))\n",
    "\n",
    "        if 'backward' in directions:\n",
    "            for variable in best_variables:\n",
    "                step_var = list(best_variables)\n",
    "                step_var.remove(variable)\n",
    "                step_model = train_model(step_var)\n",
    "                step_score = score_model(step_model, step_var)\n",
    "                step.append((step_score, variable, step_model, 'remove'))\n",
    "\n",
    "        # sort by ascending score\n",
    "        step.sort(key=lambda x: x[0])\n",
    "\n",
    "        # the first entry is the model with the lowest score\n",
    "        best_score, chosen_variable, best_model, direction = step[0]\n",
    "        if verbose:\n",
    "            print(f'Step: score={best_score:.2f}, {direction} {chosen_variable}')\n",
    "        if chosen_variable is None:\n",
    "            # step here, as adding or removing more variables is detrimental to performance\n",
    "            break\n",
    "        if direction == 'add':\n",
    "            best_variables.append(chosen_variable)\n",
    "        else:\n",
    "            best_variables.remove(chosen_variable)\n",
    "    return best_model, best_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e474473d-1721-4564-81d0-25a7471dbfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, best_variables = stepwise_selection(train_X.columns, \n",
    "                                                train_model_forward_selection,\n",
    "                                                score_model_forward_selection,\n",
    "                                                verbose=True)\n",
    "print(best_variables)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
