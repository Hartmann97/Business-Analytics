{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adf5bdad-361a-4626-b4e1-e8e35716b5da",
   "metadata": {},
   "source": [
    "#### Business Analytics FHDW 2025\n",
    "# Naives Bayes-Verfahren\n",
    "## am Beispiel der Vorhersage verzögerter Flüge\n",
    "\n",
    "In der engen Taktung internationaler Lufträume und der lokalen Organisation von teuren und komplexen Flughäfen ist der Umgang mit Verspätungen ein kritisches Thema. Es betrifft Kosten mit engen und teuren Start- und Lande-Slots, aber insbesondere auch die Sicherheit, da die Bewegungen im Luftraum nicht einfach angehalten werden können, um auf verspätete Flugzeuge zu warten und zeitliche/örtliche Abstände einzuhalten sind.\n",
    "\n",
    "Wenn wir auf Basis von Daten also Verspätungen von Flügen zuverlässig vorhersagen können, schützt das Menschen und spart viel Geld. Wir betrachten den Datensatz *FlightDelays* mit Daten amerikanischer Flughäfen und -gesellschaften. Daraus nutzen wir als Prädiktoren\n",
    "- Wochentag als 1 = Montag,..., 7 = Sonntag,\n",
    "- geplante Abflugzeit in 18 Zeitintervallen zwischen 6:00 am und 10:00 pm,\n",
    "- Herkunft als drei Flughafen-Codes DCA, IAD, BWI,\n",
    "- Zielflughäfen JFK, LGA, EWR,\n",
    "- Fluggesellschaften CO, DH, DL, MQ, OH, RU, UA, US.\n",
    "\n",
    "Zielvariable ist der *Status* als pünktlich oder verspätet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb9411-2d1f-49c2-b755-6f09152b7abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import matplotlib.pylab as plt\n",
    "from dmba import classificationSummary, gainsChart\n",
    "\n",
    "delays_df = pd.read_csv('./Daten/FlightDelays.csv')\n",
    "delays_df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d7746a-fbcd-4861-be46-d13196cf9eda",
   "metadata": {},
   "source": [
    "Gemäß der für Bayes definierten kategorischen Prädiktoren wandeln wir zunächst die Daten um und erzeugen passende Dummy-Variablen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f0a6f1-265e-43de-9cfc-0a96e11b46a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "delays_df.DAY_WEEK = delays_df.DAY_WEEK.astype('category')\n",
    "delays_df['Flight Status'] = delays_df['Flight Status'].astype('category')\n",
    "\n",
    "delays_df.CRS_DEP_TIME = [round(t/100) for t in delays_df.CRS_DEP_TIME]\n",
    "delays_df.CRS_DEP_TIME = delays_df.CRS_DEP_TIME.astype('category')\n",
    "\n",
    "predictors = ['DAY_WEEK', 'CRS_DEP_TIME', 'ORIGIN', 'DEST', 'CARRIER']\n",
    "outcome = 'Flight Status'\n",
    "X = pd.get_dummies(delays_df[predictors])\n",
    "y = delays_df[outcome].astype('category')\n",
    "classes = list(y.cat.categories)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c25684-86d9-46fc-a4fc-af0959e6888b",
   "metadata": {},
   "source": [
    "Dann teilen wir den modifizierten Datensatz in Trainings- und Validierungsdaten auf und führen den naiven Bayes mit `MultinomialNB` durch. Der Parameter `alpha` dient hier der (Laplace-)Glättung von Variablen, die in unseren Trainingsdaten nur 0-Werte besitzen. *Alpha* > 0 vermeidet ein Overfitting des Modells, so dass aus einer Stichprobe, in der eine bestimmte Kategorie fehlt, nicht deren generelle Nichtexistenz abgeleitet wird. \n",
    "\n",
    "Wir merken uns in Variablen sowohl die resultierenden Wahrscheinlichkeiten (`predict_proba`) als auch die Klassifizierungen (`predict`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e35933-1e68-4503-9c33-f24f184f86cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "\n",
    "delays_nb = MultinomialNB(alpha=0.01)\n",
    "delays_nb.fit(X_train, y_train)\n",
    "\n",
    "pred_prob_train = delays_nb.predict_proba(X_train)\n",
    "pred_prob_valid = delays_nb.predict_proba(X_valid)\n",
    "\n",
    "y_valid_pred = delays_nb.predict(X_valid)\n",
    "y_train_pred = delays_nb.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1d8540-7d0c-44b6-8c7a-2036f70ac256",
   "metadata": {},
   "source": [
    "Statt nun einfach die Ergebnisse zu verwenden, generieren wir uns Pivot-Tabellen über die von den einzelnen Prädiktoren bedingten Wahrscheinlichkeiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988bab5e-485a-4d1c-a3f0-02f6a14ab956",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(delays_df, test_size=0.4, random_state=1)\n",
    "pd.set_option('display.precision', 4)\n",
    "print(train_df['Flight Status'].value_counts() / len(train_df))\n",
    "print()\n",
    "for predictor in predictors:\n",
    "    tmp_df = train_df[['Flight Status', predictor]]\n",
    "    freq_table = tmp_df.pivot_table(index='Flight Status', columns=predictor, aggfunc=len, observed=False)\n",
    "    prop_table = freq_table.apply(lambda x: x/sum(x), axis=1)\n",
    "    print(prop_table)\n",
    "    print()\n",
    "    \n",
    "pd.reset_option('display.precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b70c211-81e8-41f7-92c2-d0aaf85dc6fb",
   "metadata": {},
   "source": [
    "Um einen neuen Flug zu klassifizieren, berechnen wir die Wahrscheinlichkeiten für Verspätung und Pünktlichkeit. Dazu brauchen wir nur die Zähler der Bayes-Formel zu vergleichen, da beide Werte den gleichen Nenner besitzen.\n",
    "\n",
    "Um z. B. einen Delta-Flug von DCA nach LGA zu klassifizieren, der sonntags zwischen 10.00 und 11.00 morgens abfliegt, berechnen wir die Zähler aus den Werten der Pivot-Tabelle oben:\n",
    "\n",
    "$P(delayed|Carrier=DL, Day Week=7, Dep Time=10, Dest=LGA, Origin=DCA) \\\\ \\propto (0.1977)(0.0958)(0.1609)(0.0307)(0.4215)(0.5211) = 0.000021$\n",
    "\n",
    "$P(ontime|Carrier=DL, Day Week=7, Dep Time=10, Dest=LGA, Origin=DCA) \\\\ \\propto (0.8023)(0.2040)(0.1048)(0.0519)(0.5779)(0.6478) = 0.00033$\n",
    "\n",
    "$\\propto$ bedeutet hier \"ist proportional zu\", da wir zunächst ja nur die Zähler ermittelt haben (es sieht auf den ersten Blick aus wie ein $\\alpha$, ist aber keins).\n",
    "\n",
    "Die Werte zeigen, dass die Pünktlichkeit des betrachteten Fluges wahrscheinlicher ist, als die Verspätung. Wichtig ist hier, zur Kenntnis zu nehmen, dass ein Datenpunkt mit genau dieser Kombination von Prädiktorwerten nicht in den Trainingsdaten vorkommt. Wir müssen also den naiven Bayes nutzen. Die tatsächlichen bedingten Wahrscheinlichkeiten können wir nun auch ermitteln:\n",
    "\n",
    "$P(delayed|Carrier=DL, Day Week=7, Dep Time=10, Dest=LGA, Origin=DCA) = \\frac{0.000021}{0.000021+0.00033} = 0.058$ \n",
    "\n",
    "$P(ontime|Carrier=DL, Day Week=7, Dep Time=10, Dest=LGA, Origin=DCA) = \\frac{0.00033}{0.000021+0.00033} = 0.942$ \n",
    "\n",
    "Die ausführliche Darstellung soll deutlich machen, wie sich - trotz der üblichen Instanzierung eines Modells und der uniformen Aufrufe von `predict` - das Modell und seine Berechnungen bei Bayes von anderen unterscheidet. Natürlich nutzen wir \"in der Realität\" bzw. in der Praxis die Funktionen der Bibliotheken, um die Wahrscheinlichkeiten für die interessanten Datensätze aus den Trainings- oder Validierungsdaten, oder für einen neuen Datenpunkt zu bestimmen. Für den Beispieldatenpunkt von oben finden wir in den Validierungsdaten die gleichen Wahrscheinlichkeiten, wie zuvor händisch berechnet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f09c9d-d8fd-45ce-8aa2-6f48e4e8e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_df = pd.concat([pd.DataFrame({'actual': y_valid, 'predicted': y_valid_pred}),\n",
    "                       pd.DataFrame(pred_prob_valid, index=y_valid.index)], axis=1)\n",
    "\n",
    "search_mask = ((X_valid.CARRIER_DL == 1) & (X_valid.DAY_WEEK_7 == 1) & (X_valid.CRS_DEP_TIME_10 == 1)\n",
    "               & (X_valid.DEST_LGA == 1) & (X_valid.ORIGIN_DCA == 1))\n",
    "\n",
    "search_df[search_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dbab4f-c069-464d-b316-7749e8743cb9",
   "metadata": {},
   "source": [
    "Zur Einschätzung der prädiktiven Performance des naiven Bayes-Klassifizierers lassen wir uns die Konfusionsmatrix angeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec1e987-2ac0-43bc-8395-e8f187c9605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificationSummary(y_train, y_train_pred, class_names=classes)\n",
    "print()\n",
    "classificationSummary(y_valid, y_valid_pred, class_names=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d46d8e5-3039-4d7f-a40e-337fa451cbde",
   "metadata": {},
   "source": [
    "Sowohl für die Trainings- als auch die Validierungsdaten liegt die Genauigkeit bei knapp 80%. Hätten wir einfach alle Datensätze als pünktlich klassifiziert, wäre die Qualität nicht viel schlechter gewesen. Ein *Gains Chart* zeigt allerdings, dass der naive Bayes die verspäteten Flüge effektiv einfängt, wenn Ranking berücksichtigt wird:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5a1619-758c-49aa-97f3-59db037c6e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "gal_df = pd.DataFrame({'actual': 1-y_valid.cat.codes, 'prob': pred_prob_valid[:, 0]})\n",
    "gal_df = gal_df.sort_values(by=['prob'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(4, 4)\n",
    "gainsChart(gal_df.actual, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08213a65-1959-4d4f-88b2-d6159b7e2a29",
   "metadata": {},
   "source": [
    "## Aufgabe\n",
    "\n",
    "Die reine Nutzung von `MultinomialNB` ist einfach. Daher schauen wir uns die unterschiedlichen Anwendungen des Satzes von Bayes am Beispiel des Datensatzes *UniversalBank.csv* noch einmal genauer an. Teilen Sie den Datensatz dazu in 60% Trainingsdaten und 40% Validierungsdaten auf.\n",
    "\n",
    "1. Generieren Sie aus den Trainingsdaten eine *Pivot-Tabelle* mit *Online als Spaltenvariable*, *CreditCard als Zeilenvariable* und *PersonalLoan als sekundärer Zeilenvariable*. Nutzen Sie dazu die Dataframe-Methoden `melt` und `pivot_table`.\n",
    "\n",
    "2. Bestimmen Sie aus der Pivot-Tabelle die Wahrscheinlichkeit, dass eine Kundin, die eine Kreditkarte besitzt und Online Banking nutzt, ein Darlehen in Anspruch nimmt (das ist die bedingte Wahrscheinlichkeit $P(Loan=1|CC=1,Online=1)$ eines Darlehens unter den Voraussetzungen Kreditkarte und Online).\n",
    "\n",
    "3. Generieren Sie zwei weitere Pivot-Tabellen aus den Trainingsdaten: Eine mit Spaltenvariable *Online*, eine mit Spaltenvariable *CreditCard*, beide mit *PersonalLoan* als Zeilenvariable.\n",
    "\n",
    "4. Bestimmen Sie folgende Wahrscheinlichkeiten aus den Werten der Pivot-Tabellen (CC = CreditCard):<br>\n",
    "$P(CC=1|Loan=1)$ <br>\n",
    "$P(Online=1|Loan=1)$<br>\n",
    "$P(Loan=1)$<br>\n",
    "$P(CC=1|Loan=0)$<br>\n",
    "$P(Online=1|Loan=0)$<br>\n",
    "$P(Loan=0)$<br>\n",
    "\n",
    "5. Ermitteln Sie aus den Werten oben die Naive-Bayes-Wahrscheinlichkeit $P_{nb}(Loan=1|CC=1,Online=1)$. Vergleichen Sie diese mit dem Wert von oben. Welches ist der genauere Wert?\n",
    "\n",
    "6. Generieren Sie für die Trainingsdaten ein Modell mit `MultinomialNB` und ermitteln Sie damit die Wahrscheinlichkeit $P(Loan=1|CC=1,Online=1)$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
