{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f97b402f-53fe-4ba7-b769-49e31f339bbf",
   "metadata": {},
   "source": [
    "#### Business Analytics FHDW 2025\n",
    "# k-Nächste Nachbarn (k-NN)\n",
    "## am Beispiel von Sitzrasenmähern\n",
    "\n",
    "Im Beispielszenario möchte ein Hersteller von Sitzrasenmähern die Haushalte einer Stadt in potentielle Käufer und Nichtkäufer einordnen. Eine Stichprobe liefert der Datensatz `RidingMowers`. Der ist für eine echte Verwertung zu klein, erfüllt aber hier seinen Zweck.\n",
    "\n",
    "Wir ergänzen die Datenpunkte um Nummern, um sie über den internen Index hinaus identifizieren zu können. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffad9da-7965-4cb6-be54-e36374b5ab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Funktion für die Darstellung des Datensatzes als Scatter Plot\n",
    "def plotDataset(ax, data, showLabel=True, **kwargs):\n",
    "    subset = data.loc[data['Ownership']=='Owner']\n",
    "    ax.scatter(subset.Income, subset.Lot_Size, marker='o',\n",
    "               label='Eigentümer' if showLabel else None, color='C1', **kwargs)\n",
    "    subset = data.loc[data['Ownership']=='Nonowner']\n",
    "    ax.scatter(subset.Income, subset.Lot_Size, marker='D',\n",
    "               label='Nichteigentümer' if showLabel else None, color='C0', **kwargs)\n",
    "    plt.xlabel('Einkommen')\n",
    "    plt.ylabel('Grundstücksgröße')\n",
    "    for _, row in data.iterrows():\n",
    "        ax.annotate(row.Number, (row.Income+2, row.Lot_Size))\n",
    "\n",
    "mower_df = pd.read_csv('./Daten/RidingMowers.csv')\n",
    "mower_df['Number'] = mower_df.index+1\n",
    "\n",
    "mower_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29f509b-0265-4a00-88ba-d4741d423153",
   "metadata": {},
   "source": [
    "Auch, wenn wir in diesem Beispiel aus Gründen der Anschaulichkeit nur wenige Daten haben, teilen wir Trainings- und Validierungsdaten ab.\n",
    "\n",
    "Dann erzeugen wir einen neuen Haushalt `new_household` mit einem Einkommen von 60.000 und einem Grundstück von 2.000.\n",
    "\n",
    "Alle Daten - mit dem neuen Haushalt - stellen wir graphisch dar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90bf254-4f04-4a46-b275-15713bd969aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = train_test_split(mower_df, test_size=0.4, random_state=26)\n",
    "\n",
    "new_household = pd.DataFrame([{'Income': 60, 'Lot_Size': 20}])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plotDataset(ax, train_data)\n",
    "# Validierungsdatenpunkte sind farblich nicht ausgefüllt:\n",
    "plotDataset(ax, valid_data, showLabel=False, facecolors='none')\n",
    "ax.scatter(new_household.Income, new_household.Lot_Size, marker='*',\n",
    "           label='Neuer Haushalt', color='black', s=150)\n",
    "\n",
    "plt.xlabel('Einkommen')\n",
    "plt.ylabel('Grundstücksgröße')\n",
    "ax.set_xlim(40, 115)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b14f949-177d-4cdb-ae39-97f170019872",
   "metadata": {},
   "source": [
    "Dem neuen Haushalt euklidisch am nächsten ist der Trainings-Datensatz 4 mit einem Einkommen von 61.500 und einem Grundstück von 2.080. Nutzen wir hier 1-NN, würden wir den neuen Haushalt wie 4 als Eigentümer klassifizieren. Nutzen wir $k=3$, sind die nächsten Nachbarn 4, 14 und 1. Zwei davon sind Eigentümer; diese Mehrheit würde wieder zur dieser Klassifizierung führen.\n",
    "\n",
    "Das können wir rechnerisch bestätigen. Da wir Einkommen und Grundstücksgröße als Prädiktoren nutzen wollen - Geld und Fläche - müssen wir diese Daten zunächst normieren. Danach liefert uns ein `NearestNeighbors`-Objekt aus *scikit-learn* mit `fit` die Anpassung unserer Trainingsdaten, so dass wir mit `kneighbors` die drei Nachbarn unseres neuen Haushalts bekommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9841a2-3c1c-437d-ab10-f92ca0c2bcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(train_data[['Income', 'Lot_Size']])\n",
    "\n",
    "mower_norm = pd.concat([pd.DataFrame(scaler.transform(mower_df[['Income', 'Lot_Size']]),\n",
    "                                     columns=['zIncome', 'zLot_Size']),\n",
    "                        mower_df[['Ownership', 'Number']]], axis=1)\n",
    "train_norm = mower_norm.iloc[train_data.index]\n",
    "valid_norm = mower_norm.iloc[valid_data.index]\n",
    "new_household_norm = pd.DataFrame(scaler.transform(new_household),\n",
    "                                  columns=['zIncome', 'zLot_Size'])\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=3)\n",
    "knn.fit(train_norm.iloc[:, 0:2])\n",
    "distances, indices = knn.kneighbors(new_household_norm)\n",
    "\n",
    "train_norm.iloc[indices[0], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb654d-88ae-45dd-b00e-52ba98f7c223",
   "metadata": {},
   "source": [
    "## Was für ein $k$ sollten wir wählen?\n",
    "\n",
    "Ist $k$ zu niedrig, besteht die Gefahr, dass diese (Über-)Anpassung sich auf das Rauschen in den Daten bezieht. Höhere Werte glätten das weg, zu hohe $k$ ignorieren aber die lokalen Strukturen, die gerade diese Methode gut nutzen kann. Im Extremfall $k=n$ landen wir bei einem naiven Ansatz einer Gesamtmehrheit. Wir müssen also ein Gleichgewicht finden zwischen Überanpassung an die Prädiktorinformationen und dem vollständigen Ignorieren dieser.\n",
    "\n",
    "Praktischerweise nutzen wir Rechner und können daher schlicht ausprobieren (lassen), welches $k$ die beste Klassifikationsperformance bzw. den kleinsten Fehler liefert. Allgemein sollte das gewählte $k$ aber ungerade sein, damit es nicht zu \"unentschieden\" bei der Mehrheitssuche kommt.\n",
    "\n",
    "Im Folgenden müssen wir beachten, dass hier der Trainingsprozess die Validierungsdaten nutzt, um das beste $k$ zu ermitteln. Eigentlich bräuchten wir also einen dritten Test, um die Qualität der Prädiktion bei Datensätzen zu prüfen, die das Verfahren hier \"noch nicht kennt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3c8eec-ea15-4a4f-af0a-3f437bc800ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_norm[['zIncome', 'zLot_Size']]\n",
    "train_y = train_norm['Ownership']\n",
    "valid_X = valid_norm[['zIncome', 'zLot_Size']]\n",
    "valid_y = valid_norm['Ownership']\n",
    "results = []\n",
    "for k in range(1, 15):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k).fit(train_X, train_y)\n",
    "    results.append({\n",
    "        'k': k,\n",
    "        'accuracy': accuracy_score(valid_y, knn.predict(valid_X))\n",
    "    })\n",
    "    \n",
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ca8279-9772-4384-85fe-49b524e3be69",
   "metadata": {},
   "source": [
    "Wählen wir mit diesen Informationen nun $k=4$, ergibt sich das hier endgültige Prädiktionsobjekt, mit dem wir den neuen Haushalt von oben klassifizieren und uns die zugehörigen Parameter ausgeben lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91611ca-7c85-486a-a4ed-d6fcff6ccf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mower_X = mower_norm[['zIncome', 'zLot_Size']]\n",
    "mower_y = mower_norm['Ownership']\n",
    "knn = KNeighborsClassifier(n_neighbors=4).fit(mower_X, mower_y)\n",
    "\n",
    "distances, indices = knn.kneighbors(new_household_norm)\n",
    "print(knn.predict(new_household_norm))\n",
    "print('Distances', distances)\n",
    "print(mower_norm.iloc[indices[0], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd759f1-13da-4bd9-b050-33dbf8469f72",
   "metadata": {},
   "source": [
    "## Setzen einer Schwelle/Cutoff\n",
    "\n",
    "Die Mehrheitsentscheidung bei k-NN kann praktisch auf einen Cutoff-Wert abgebildet werden. Zunächst können wir die Verhältnisse der nachbarlichen Klassenzugehörigkeiten als Wahrscheinlichkeiten interpretieren, mit denen unser zu klassifizierender Datensatz einer davon angehört. Z. B. ergaben sich für unseren neuen Haushalt bei $k=4$ drei Eigentümer, d. h. eine Wahrscheinlichkeit von 0.75 für Eigentümer, 0.25 für Nichteigentümer.\n",
    "\n",
    "Die einfache Mehrheitsregel entspricht also einem Cutoff von 0.5. Bei Bedarf können wir auf Basis der Wahrscheinlichkeiten eine andere Schwelle definieren, je nachdem, ob wir die Genauigkeit maximieren wollen, oder die Kosten für Fehlklassifikationen berücksichtigen müssen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5994c478-8eb6-4425-af2a-e63e5914d077",
   "metadata": {},
   "source": [
    "## Aufgabe\n",
    "\n",
    "Wir betrachten den bekannten Datensatz *BostonHousing.csv* über Stadtgebiete (*tracts*) im Rahmen einer Volkszählung. Die Daten weisen ein ethisches Problem auf (Kategorie *b*, \"the proportion of blacks by town\", im Jahre 1978 offenbar ein akzeptiertes Kriterium, heute in der Literatur oft einfach ausgelassen), das wir an dieser Stelle nur technisch lösen können.\n",
    "\n",
    "Ermitteln Sie ein geeignetes k-NN-Vorhersagemodell für die Zielvariable *medv* (Medianwert von eigentümerbewohnten Häusern in $ 1.000):\n",
    "* Berücksichtigen Sie alle 12 Prädiktoren.\n",
    "* Prüfen Sie *k* von 1 bis 5. Was ist das beste *k*, was bedeutet der Wert?\n",
    "* Wir haben es nun mit einer numerischen Zielvariable zu tun, Sie benötigen also den `KNeighborsRegressor` und auch einen geeigneten Wert (statt `accuracy_score`) zur Beurteilung der *k*s.\n",
    "* Denken Sie an die Normierung der Daten.\n",
    "\n",
    "Sagen Sie mit dem besten *k* den Zielwert für den neuen Datenpunkt `{'crim': 0.2, 'zn': 0, 'indus':7, 'chas':0, 'nox':0.538, 'rm': 6, 'age':62, 'dis':4.7, 'rad':4, 'tax':307, 'ptratio':21, 'lstat':10}` voraus."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
