{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "381299e0-d72a-43d1-9421-6920a22c354b",
   "metadata": {},
   "source": [
    "#### Business Analytics FHDW 2025\n",
    "\n",
    "# Künstliche Neuronale Netze mit TensorFlow und Keras\n",
    "\n",
    "Falls *TensorFlow* noch nicht installiert ist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519977b5-ee0a-4933-901e-589e92e64766",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e65eda-24a4-47f1-9d71-de155e3eb293",
   "metadata": {},
   "source": [
    "*Keras* ist ein Bestandteil der *TensorFlow*-Bibliothek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7b4892-4f15-4200-8bdf-8e84f840f190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from dmba import regressionSummary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a0683-5628-4c4e-b900-710ad78a575d",
   "metadata": {},
   "source": [
    "Als Beispiel betrachten wir die Daten aus `TinyData.csv`. Numerische Nahrungsbestandteile aus *Fett* und *Salz* werden dort der kategorischen Einordnung in *schmeckt* oder *schmeckt nicht* zugeordnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d0352b-3b34-475e-9c9a-027c2fd94b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_example_df = pd.read_csv('./Daten/TinyData.csv')\n",
    "tiny_example_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1979289f-fab4-4243-9c2a-225b57013c85",
   "metadata": {},
   "source": [
    "Die Daten bereiten wir passend als Prädiktoren und Ziel auf. Wie gewohnt wird aus den Kategorien eine Dummy-Variable *like*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edff5ed-df36-40ce-9a12-42fd2b708b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['fat', 'salt']\n",
    "outcome = 'acceptance'\n",
    "\n",
    "X = tiny_example_df[predictors]\n",
    "y = pd.get_dummies(tiny_example_df[outcome], drop_first=True)\n",
    "classes = sorted(tiny_example_df[outcome].unique())\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a354d5a-31f7-4411-80d3-3b6b86c2b369",
   "metadata": {},
   "source": [
    "Nun konstruieren wir ein einfaches Netz aus den bekannten, dicht verknüpften *Multilayer Perceptrons* (MLP). Die dichte Verknüpfung, d. h. alle Inputs der Knoten einer Schicht sind jeweils mit allen Outputs der vorherigen Schicht verbunden, erreichen wir hier durch Verwendung von `tensorflow.keras.layers.Dense`. Ein solcher Dense Layer impliziert diese Eigenschaft, wenn wir ihn mit anderen verknüpfen.\n",
    "\n",
    "Wir nutzen die *Functional API* von Keras, d. h. die einzelnen Schichten werden als Funktionen definiert und auch funktional miteinander verbunden, indem die Ergebnisse der vorherigen Schicht als Parameter der folgenden Schicht dienen.\n",
    "\n",
    "Es geht los mit einer Eingabe-Schicht `inputs`, die einen zweidimensionalen Vektor der Fett- und Salz-Werte akzeptiert. Genau genommen ist die erste Schicht damit eigentlich ein Tensor. Dieser wird übergeben an eine \"verborgene\" Dichte-Schicht `x`, die aus drei Knoten besteht, die durch logistische Sigmoid-Funktionen aktiviert werden. `x` wird an die Ausgabe-Schicht `outputs` übergeben, deren einzelner Knoten die drei Ergebnisse der versteckten Knoten auf den gesuchten Akzeptanzwert reduziert.\n",
    "\n",
    "Mit den so erzeugten Variablen `inputs` und `outputs` können wir das Modell instanzieren und uns seine Eigenschaften und Struktur ausgeben lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cd6dd8-e557-4a58-92f5-593b27cba860",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(2,), name='Input_fat_and_salt')\n",
    "x = layers.Dense(3, activation='sigmoid', name='Hidden_Layer')(inputs)\n",
    "outputs = layers.Dense(1, name='Output_acceptance')(x)\n",
    "\n",
    "tiny_model = keras.Model(inputs=inputs, outputs=outputs, name=\"tiny_model\")\n",
    "tiny_model.summary()\n",
    "keras.utils.plot_model(tiny_model, show_shapes=True, dpi=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b575479-6986-4f04-92e3-82d97a6aee69",
   "metadata": {},
   "source": [
    "Das Modell kompilieren wir und trainieren es mit `fit`. Wegen der 10.000 Durchläufe unterdrücken wir die Ausgaben (`verbose`),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d96493-8997-4651-9d69-2884453fa61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_model.compile(loss='mean_squared_error',\n",
    "                   optimizer='adam',\n",
    "                   metrics=['accuracy'])\n",
    "tiny_model.fit(x=X, y=y, epochs=10000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824749ed-5ee5-4dab-aa0b-52da9df3b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_model.save('./tiny_model.keras') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d30ec0-13c8-4393-9619-56ddf633a505",
   "metadata": {},
   "source": [
    "Alternativ laden wir das bereits berechnete Modell wieder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3968f647-cb4d-41ce-8a7b-2122c410de93",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_model =  tf.keras.models.load_model('./tiny_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26abb2f-89a1-4a95-8c2c-ccf05c8ede26",
   "metadata": {},
   "source": [
    "Die resultierenden Gewichte des Modells, sowie seine Performance bzw. Vorhersagequalität geben wir aus. Da die Zielvariable zwar kategorisch ist, das Netz aber numerische Werte, die wir als Wahrscheinlichkeiten interpretieren können, erzeugt, werten wir die Ergebnisse wie eine Regression aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d0a66c-3618-4ef9-90ee-67b04a5de6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in tiny_model.layers: \n",
    "    print(layer.get_weights())\n",
    "\n",
    "arr = [(1-a, a) for a in tiny_model.predict(X)]\n",
    "print(pd.concat([\n",
    "    tiny_example_df,\n",
    "    pd.DataFrame(arr, columns=classes)\n",
    "], axis=1))\n",
    "print(y-tiny_model.predict(X))\n",
    "print(regressionSummary(y, tiny_model.predict(X)))\n",
    "\n",
    "test_scores = tiny_model.evaluate(X, y, verbose=2)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36a248e-2cc7-4d16-a161-d32422b9e578",
   "metadata": {},
   "source": [
    "## Aufgabe\n",
    "\n",
    "Implementieren Sie ein XOR-Gatter als KNN mit der *Functional API* von Keras. Trainieren Sie das Netz und überprüfen Sie die Gewichte.\n",
    "\n",
    "`training_bits = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])`\n",
    "\n",
    "`target_bits = np.array([[0], [1], [1], [0]])`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
