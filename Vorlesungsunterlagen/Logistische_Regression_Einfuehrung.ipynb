{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36ab8ed4-7305-4507-a9fa-7cb64b2fc063",
   "metadata": {},
   "source": [
    "#### Business Analytics FHDW 2025\n",
    "# Ein erstes kleines Beispiel zur logistischen Regression\n",
    "## zur Illustration praktischer Aspekte\n",
    "\n",
    "Wir betrachten den bekannten Datensatz *UniversalBank.csv* und führen damit eine einfache logistische Regression durch. Sie soll auf Basis des Einkommens voraussagen, ob ein Kunde/eine Kundin ein Angebot über ein Darlehen annehmen würde.\n",
    "\n",
    "Zunächst bereiten wir den Datensatz auf die bereits bekannte Weise vor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc15c3c-347e-4803-8271-d472c612df54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from dmba import classificationSummary\n",
    "\n",
    "bank_df = pd.read_csv('./Daten/UniversalBank.csv')\n",
    "print(bank_df.head)\n",
    "\n",
    "y = bank_df['PersonalLoan']\n",
    "X = bank_df[['Income']]\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d61345b-1cc3-4824-8a49-edeb7b518b5b",
   "metadata": {},
   "source": [
    "Die Durchführung der logistischen Regression über die Anpassung an die Trainingsdaten mit `fit` ist dann auch gewohnt einfach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba7c39c-6c1c-44b2-924b-222e02c77cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d9e181-3867-4a87-a322-39db6dfd7c43",
   "metadata": {},
   "source": [
    "Wir konstruieren uns daraus einmal selbst die Funktion zur Bestimmung der bedingten Wahrscheinlichkeiten. Wir nutzen nur einen Prädiktor, also haben wir $p(loan = yes | income = x) = \\frac{1}{1+e^{-(\\beta_0 + \\beta_1 x)}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59f4160-66b3-4f09-a054-33ee867231d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = lr.intercept_[0]\n",
    "coeff = lr.coef_[0][0]\n",
    "\n",
    "x = np.arange(0, 250, 1) # Skaliert auf Basis der Einkommensspanne\n",
    "P = 1/(1+np.exp(-1*(intercept+coeff*x)))\n",
    "\n",
    "print(intercept, coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b738bfa-b9e0-4c66-b29e-c0d3385a6d83",
   "metadata": {},
   "source": [
    "Für die gesuchten Betas greifen wir auf die Attribute der `LogisticRegression` zu. $\\beta_0$ finden wir in `intercept_`, $\\beta_1$ in `coef_`. Unsere angepasste Funktion ist dann $p(loan = yes | income = x) = \\frac{1}{1+e^{6.063 - 0.036 x}}$. Werfen wir einen Blick darauf, zusammen mit den Darlehensentscheidungen aus dem Datensatz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d8ad2f-7771-4c2c-a4d6-ee6f4442b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,P)\n",
    "plt.scatter(bank_df['Income'], bank_df['PersonalLoan'], s=10)\n",
    "plt.title('Wahrscheinlichkeiten und tatsächliche Entscheidungen für Darlehen')\n",
    "plt.xlabel('Einkommen')\n",
    "plt.ylabel('P für Darlehen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76dd396-e79c-430f-85f7-f0cd1930cb80",
   "metadata": {},
   "source": [
    "Als Chancen bzw. Odds können wir das auch darstellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b281bd-6a46-41df-9077-0f62e1a99682",
   "metadata": {},
   "outputs": [],
   "source": [
    "Odds = np.exp(intercept+coeff*x)\n",
    "       \n",
    "plt.plot(x,Odds)\n",
    "plt.title('Chancen für Annahme Darlehen')\n",
    "plt.xlabel('Einkommen')\n",
    "plt.ylabel('Odds')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a2f9b8-2f81-44a0-a8de-6b71b0238929",
   "metadata": {},
   "source": [
    "Bis jetzt haben wir uns mit den bedingten Wahrscheinlichkeiten beschäftigt. Ursprünglich wollen wir mit der logistischen Regression aber eine binäre Prognose erhalten, in diesem Fall *Darlehen ja oder nein*. Dazu können wir wieder die Funktion `predict` nutzen. Für die Beurteilung der Performance nutzen wir hier eine Konfusionsmatrix, jeweils für die Trainings- und die Validierungsdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8994fabd-c064-4b52-850d-2282472b1941",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificationSummary(train_y, lr.predict(train_X))\n",
    "print('')\n",
    "classificationSummary(valid_y, lr.predict(valid_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a1db1d-e1e0-4416-85f0-882c6922fc0c",
   "metadata": {},
   "source": [
    "Um aus den Wahrscheinlichkeiten zur binären Entscheidung zu kommen, wendet die Funktion eine Schwelle bzw. den *cutoff* $c$ an. Liegt die prognostizierte Wahrscheinlichkeit eines Datensatzes auf oder über $c$, wird angenommen, dass der Kunde/die Kundin das Darlehen akzeptiert, also Ereignis $1$ eintritt, sonst $0$. Im Falle der hier genutzten Funktion `predict` von *scikit learn* besitzt $c$ einen *default*-Wert von $0.5$. Überprüfen wir das kurz selbst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed53364-e50e-479f-ae21-92b7be00e6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = np.where(P[train_X] >= 0.5, 1, 0)\n",
    "valid_predictions = np.where(P[valid_X] >= 0.5, 1, 0)\n",
    "classificationSummary(train_y, train_predictions)\n",
    "print('')\n",
    "classificationSummary(valid_y, valid_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6923c46-29da-4c9e-a8b4-8e8dde3273b5",
   "metadata": {},
   "source": [
    "Und noch eine Darstellung der ermittelten Wahrscheinlichkeitsfunktion und der Prädiktionen der Trainingsdatensätze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21949b8c-5fcc-4a03-9138-85938b00d51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, P, color='r')\n",
    "plt.scatter(train_X['Income'], lr.predict_proba(train_X)[:,1], s=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc8b17e-6fa3-493d-869e-3b22b0c2df7d",
   "metadata": {},
   "source": [
    "## Aufgabe\n",
    "Analysieren Sie die Auswirkungen verschiedener *cutoff*-Werte im gegebenen Modell auf geeignete Weise: Generieren Sie einen `scatter`-Graphen mit *cutoff*-Werten auf der x-Achse und der resultierenden Genauigkeit auf der y-Achse. `accuracy_score` von *scikit learn* kann dabei hilfreich sein."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
